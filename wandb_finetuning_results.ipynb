{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse WandB Pretraining Data\n",
    "resources used for this notebook:\n",
    "* https://docs.wandb.ai/guides/track/public-api-guide/\n",
    "* https://docs.wandb.ai/ref/python/public-api/runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Results\n",
    "adapted from: https://docs.wandb.ai/guides/track/public-api-guide/ (22.07.2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity, project = \"josefine-busch-htw-berlin\", \"ma_finetuning\"\n",
    "runs = api.runs(f\"{entity}/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_al...</td>\n",
       "      <td>0.781757</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.781689</td>\n",
       "      <td>0.782212</td>\n",
       "      <td>0.781810</td>\n",
       "      <td>0.564022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_al...</td>\n",
       "      <td>0.761486</td>\n",
       "      <td>0.491612</td>\n",
       "      <td>0.761060</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.761606</td>\n",
       "      <td>0.525209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_no...</td>\n",
       "      <td>0.790089</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.789909</td>\n",
       "      <td>0.790954</td>\n",
       "      <td>0.790031</td>\n",
       "      <td>0.580984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_no...</td>\n",
       "      <td>0.788958</td>\n",
       "      <td>0.482180</td>\n",
       "      <td>0.788673</td>\n",
       "      <td>0.790696</td>\n",
       "      <td>0.789038</td>\n",
       "      <td>0.579731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_ta...</td>\n",
       "      <td>0.676998</td>\n",
       "      <td>0.587859</td>\n",
       "      <td>0.672606</td>\n",
       "      <td>0.688836</td>\n",
       "      <td>0.677988</td>\n",
       "      <td>0.366663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>HF_HF_5M_RC_150K_3_v11_3e-5_prom_prom_300_all_...</td>\n",
       "      <td>0.883277</td>\n",
       "      <td>0.373002</td>\n",
       "      <td>0.882915</td>\n",
       "      <td>0.887143</td>\n",
       "      <td>0.882942</td>\n",
       "      <td>0.770074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>HF_HF_5M_RC_150K_42_v11_3e-5_prom_prom_300_tat...</td>\n",
       "      <td>0.621533</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>0.619100</td>\n",
       "      <td>0.628663</td>\n",
       "      <td>0.624230</td>\n",
       "      <td>0.252854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>HF_HF_5M_RC_150K_199_v11_3e-5_prom_prom_300_ta...</td>\n",
       "      <td>0.639478</td>\n",
       "      <td>0.674505</td>\n",
       "      <td>0.638230</td>\n",
       "      <td>0.644538</td>\n",
       "      <td>0.641600</td>\n",
       "      <td>0.286123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>HF_HF_5M_RC_150K_3_v11_3e-5_prom_prom_300_nota...</td>\n",
       "      <td>0.918787</td>\n",
       "      <td>0.270507</td>\n",
       "      <td>0.918784</td>\n",
       "      <td>0.919091</td>\n",
       "      <td>0.918949</td>\n",
       "      <td>0.838040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>HF_HF_5M_RC_150K_3_v11_3e-5_prom_prom_300_tata...</td>\n",
       "      <td>0.624796</td>\n",
       "      <td>0.684020</td>\n",
       "      <td>0.622577</td>\n",
       "      <td>0.631623</td>\n",
       "      <td>0.627405</td>\n",
       "      <td>0.258993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              run_name  test_accuracy  \\\n",
       "0    HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_al...       0.781757   \n",
       "1    HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_al...       0.761486   \n",
       "2    HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_no...       0.790089   \n",
       "3    HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_no...       0.788958   \n",
       "4    HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_ta...       0.676998   \n",
       "..                                                 ...            ...   \n",
       "310  HF_HF_5M_RC_150K_3_v11_3e-5_prom_prom_300_all_...       0.883277   \n",
       "311  HF_HF_5M_RC_150K_42_v11_3e-5_prom_prom_300_tat...       0.621533   \n",
       "312  HF_HF_5M_RC_150K_199_v11_3e-5_prom_prom_300_ta...       0.639478   \n",
       "313  HF_HF_5M_RC_150K_3_v11_3e-5_prom_prom_300_nota...       0.918787   \n",
       "314  HF_HF_5M_RC_150K_3_v11_3e-5_prom_prom_300_tata...       0.624796   \n",
       "\n",
       "     test_loss   test_f1  test_precision  test_recall  test_mcc  \n",
       "0     0.472779  0.781689        0.782212     0.781810  0.564022  \n",
       "1     0.491612  0.761060        0.763607     0.761606  0.525209  \n",
       "2     0.469136  0.789909        0.790954     0.790031  0.580984  \n",
       "3     0.482180  0.788673        0.790696     0.789038  0.579731  \n",
       "4     0.587859  0.672606        0.688836     0.677988  0.366663  \n",
       "..         ...       ...             ...          ...       ...  \n",
       "310   0.373002  0.882915        0.887143     0.882942  0.770074  \n",
       "311   0.678970  0.619100        0.628663     0.624230  0.252854  \n",
       "312   0.674505  0.638230        0.644538     0.641600  0.286123  \n",
       "313   0.270507  0.918784        0.919091     0.918949  0.838040  \n",
       "314   0.684020  0.622577        0.631623     0.627405  0.258993  \n",
       "\n",
       "[315 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, tags, test_accuracies, test_losses, test_f1, test_precision, test_recall, test_mcc = [], [], [], [], [], [], [], []\n",
    "for run in runs:\n",
    "\tnames.append(run.name)\n",
    "\ttags.append(run.tags)\n",
    "\ttest_accuracies.append(run.summary.get(\"test/accuracy\", np.nan))\n",
    "\ttest_losses.append(run.summary.get(\"test/loss\", np.nan))\n",
    "\ttest_f1.append(run.summary.get(\"test/f1\", np.nan))\n",
    "\ttest_precision.append(run.summary.get(\"test/precision\", np.nan))\n",
    "\ttest_recall.append(run.summary.get(\"test/recall\", np.nan))\n",
    "\ttest_mcc.append(run.summary.get(\"test/matthews_correlation\", np.nan))\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "\t{\n",
    "\t\"run_name\": names,\n",
    "\t\"test_accuracy\": test_accuracies, \"test_loss\": test_losses, \"test_f1\": test_f1,\n",
    "\t\"test_precision\": test_precision, \"test_recall\": test_recall, \"test_mcc\": test_mcc}\n",
    ")\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>task</th>\n",
       "      <th>subtask</th>\n",
       "      <th>scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_al...</td>\n",
       "      <td>0.781757</td>\n",
       "      <td>0.472779</td>\n",
       "      <td>0.781689</td>\n",
       "      <td>0.782212</td>\n",
       "      <td>0.781810</td>\n",
       "      <td>0.564022</td>\n",
       "      <td>14290</td>\n",
       "      <td>hf_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_all</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_al...</td>\n",
       "      <td>0.761486</td>\n",
       "      <td>0.491612</td>\n",
       "      <td>0.761060</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.761606</td>\n",
       "      <td>0.525209</td>\n",
       "      <td>14293</td>\n",
       "      <td>hs_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_all</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_no...</td>\n",
       "      <td>0.790089</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.789909</td>\n",
       "      <td>0.790954</td>\n",
       "      <td>0.790031</td>\n",
       "      <td>0.580984</td>\n",
       "      <td>14290</td>\n",
       "      <td>hf_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_notata</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_no...</td>\n",
       "      <td>0.788958</td>\n",
       "      <td>0.482180</td>\n",
       "      <td>0.788673</td>\n",
       "      <td>0.790696</td>\n",
       "      <td>0.789038</td>\n",
       "      <td>0.579731</td>\n",
       "      <td>14293</td>\n",
       "      <td>hs_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_notata</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_ta...</td>\n",
       "      <td>0.676998</td>\n",
       "      <td>0.587859</td>\n",
       "      <td>0.672606</td>\n",
       "      <td>0.688836</td>\n",
       "      <td>0.677988</td>\n",
       "      <td>0.366663</td>\n",
       "      <td>14290</td>\n",
       "      <td>hf_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_tata</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            run_name  test_accuracy  \\\n",
       "0  HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_al...       0.781757   \n",
       "1  HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_al...       0.761486   \n",
       "2  HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_no...       0.790089   \n",
       "3  HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_no...       0.788958   \n",
       "4  HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_ta...       0.676998   \n",
       "\n",
       "   test_loss   test_f1  test_precision  test_recall  test_mcc job_id  \\\n",
       "0   0.472779  0.781689        0.782212     0.781810  0.564022  14290   \n",
       "1   0.491612  0.761060        0.763607     0.761606  0.525209  14293   \n",
       "2   0.469136  0.789909        0.790954     0.790031  0.580984  14290   \n",
       "3   0.482180  0.788673        0.790696     0.789038  0.579731  14293   \n",
       "4   0.587859  0.672606        0.688836     0.677988  0.366663  14290   \n",
       "\n",
       "         tokenizer       task           subtask   scenario  \n",
       "0  hf_5M_tokenizer  prom_core     prom_core_all  scenario1  \n",
       "1  hs_5M_tokenizer  prom_core     prom_core_all  scenario1  \n",
       "2  hf_5M_tokenizer  prom_core  prom_core_notata  scenario1  \n",
       "3  hs_5M_tokenizer  prom_core  prom_core_notata  scenario1  \n",
       "4  hf_5M_tokenizer  prom_core    prom_core_tata  scenario1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df = pd.DataFrame(tags, columns=['job_id', 'tokenizer', 'task', 'subtask', 'scenario'])\n",
    "tagged_runs = pd.concat([runs_df, tags_df], axis=1)\n",
    "tagged_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>subtask</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">p_covid</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">p_covid_sub</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.725907</td>\n",
       "      <td>0.742033</td>\n",
       "      <td>0.728841</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.724557</td>\n",
       "      <td>0.690772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.726670</td>\n",
       "      <td>0.745418</td>\n",
       "      <td>0.730243</td>\n",
       "      <td>0.739790</td>\n",
       "      <td>0.725364</td>\n",
       "      <td>0.691687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.726403</td>\n",
       "      <td>0.742635</td>\n",
       "      <td>0.729169</td>\n",
       "      <td>0.737896</td>\n",
       "      <td>0.725061</td>\n",
       "      <td>0.691395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.716138</td>\n",
       "      <td>0.758272</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>0.730047</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.679951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.714854</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>0.718047</td>\n",
       "      <td>0.728335</td>\n",
       "      <td>0.713597</td>\n",
       "      <td>0.678488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">prom_300</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">prom_300_all</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.871378</td>\n",
       "      <td>0.352145</td>\n",
       "      <td>0.871338</td>\n",
       "      <td>0.871839</td>\n",
       "      <td>0.871411</td>\n",
       "      <td>0.743249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.878510</td>\n",
       "      <td>0.338742</td>\n",
       "      <td>0.878417</td>\n",
       "      <td>0.879330</td>\n",
       "      <td>0.878394</td>\n",
       "      <td>0.757722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.349040</td>\n",
       "      <td>0.873853</td>\n",
       "      <td>0.874168</td>\n",
       "      <td>0.873923</td>\n",
       "      <td>0.748091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.869163</td>\n",
       "      <td>0.338676</td>\n",
       "      <td>0.869140</td>\n",
       "      <td>0.869476</td>\n",
       "      <td>0.869212</td>\n",
       "      <td>0.738688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.868919</td>\n",
       "      <td>0.339153</td>\n",
       "      <td>0.868884</td>\n",
       "      <td>0.869356</td>\n",
       "      <td>0.868965</td>\n",
       "      <td>0.738321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">prom_300_notata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.915688</td>\n",
       "      <td>0.262344</td>\n",
       "      <td>0.915669</td>\n",
       "      <td>0.916373</td>\n",
       "      <td>0.915885</td>\n",
       "      <td>0.832257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.915123</td>\n",
       "      <td>0.259944</td>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.916113</td>\n",
       "      <td>0.915363</td>\n",
       "      <td>0.831475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.912296</td>\n",
       "      <td>0.267181</td>\n",
       "      <td>0.912253</td>\n",
       "      <td>0.913449</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.825948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.909239</td>\n",
       "      <td>0.267065</td>\n",
       "      <td>0.909214</td>\n",
       "      <td>0.910094</td>\n",
       "      <td>0.909452</td>\n",
       "      <td>0.819545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.910600</td>\n",
       "      <td>0.266214</td>\n",
       "      <td>0.910579</td>\n",
       "      <td>0.911293</td>\n",
       "      <td>0.910784</td>\n",
       "      <td>0.822077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">prom_300_tata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.627877</td>\n",
       "      <td>0.659496</td>\n",
       "      <td>0.623024</td>\n",
       "      <td>0.639055</td>\n",
       "      <td>0.630745</td>\n",
       "      <td>0.269551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.632409</td>\n",
       "      <td>0.664721</td>\n",
       "      <td>0.631270</td>\n",
       "      <td>0.635752</td>\n",
       "      <td>0.633645</td>\n",
       "      <td>0.269383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.628784</td>\n",
       "      <td>0.656574</td>\n",
       "      <td>0.622511</td>\n",
       "      <td>0.643726</td>\n",
       "      <td>0.632432</td>\n",
       "      <td>0.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.617002</td>\n",
       "      <td>0.656175</td>\n",
       "      <td>0.601076</td>\n",
       "      <td>0.640462</td>\n",
       "      <td>0.620445</td>\n",
       "      <td>0.258924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.617183</td>\n",
       "      <td>0.654632</td>\n",
       "      <td>0.600313</td>\n",
       "      <td>0.642398</td>\n",
       "      <td>0.621084</td>\n",
       "      <td>0.261226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">prom_core</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">prom_core_all</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.775473</td>\n",
       "      <td>0.484761</td>\n",
       "      <td>0.775374</td>\n",
       "      <td>0.776058</td>\n",
       "      <td>0.775523</td>\n",
       "      <td>0.551580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.777290</td>\n",
       "      <td>0.485933</td>\n",
       "      <td>0.776954</td>\n",
       "      <td>0.779143</td>\n",
       "      <td>0.777390</td>\n",
       "      <td>0.556528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.777346</td>\n",
       "      <td>0.481766</td>\n",
       "      <td>0.777287</td>\n",
       "      <td>0.777715</td>\n",
       "      <td>0.777388</td>\n",
       "      <td>0.555102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.764337</td>\n",
       "      <td>0.491055</td>\n",
       "      <td>0.763688</td>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.764475</td>\n",
       "      <td>0.532029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.765803</td>\n",
       "      <td>0.498189</td>\n",
       "      <td>0.765413</td>\n",
       "      <td>0.767783</td>\n",
       "      <td>0.765910</td>\n",
       "      <td>0.533689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">prom_core_notata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.787790</td>\n",
       "      <td>0.466253</td>\n",
       "      <td>0.787553</td>\n",
       "      <td>0.789133</td>\n",
       "      <td>0.787812</td>\n",
       "      <td>0.576942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.786132</td>\n",
       "      <td>0.464216</td>\n",
       "      <td>0.785875</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.786096</td>\n",
       "      <td>0.573447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.786048</td>\n",
       "      <td>0.467033</td>\n",
       "      <td>0.785691</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.786095</td>\n",
       "      <td>0.574132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.790277</td>\n",
       "      <td>0.474335</td>\n",
       "      <td>0.790163</td>\n",
       "      <td>0.790980</td>\n",
       "      <td>0.790310</td>\n",
       "      <td>0.581289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.784813</td>\n",
       "      <td>0.471370</td>\n",
       "      <td>0.784727</td>\n",
       "      <td>0.785285</td>\n",
       "      <td>0.784818</td>\n",
       "      <td>0.570103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">prom_core_tata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.704405</td>\n",
       "      <td>0.585505</td>\n",
       "      <td>0.702287</td>\n",
       "      <td>0.710445</td>\n",
       "      <td>0.704728</td>\n",
       "      <td>0.415053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.710350</td>\n",
       "      <td>0.583134</td>\n",
       "      <td>0.707155</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>0.710653</td>\n",
       "      <td>0.430899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.701468</td>\n",
       "      <td>0.575317</td>\n",
       "      <td>0.700007</td>\n",
       "      <td>0.705959</td>\n",
       "      <td>0.701864</td>\n",
       "      <td>0.407780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.704527</td>\n",
       "      <td>0.610615</td>\n",
       "      <td>0.703890</td>\n",
       "      <td>0.706026</td>\n",
       "      <td>0.704399</td>\n",
       "      <td>0.410419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.702374</td>\n",
       "      <td>0.614878</td>\n",
       "      <td>0.701044</td>\n",
       "      <td>0.705566</td>\n",
       "      <td>0.702328</td>\n",
       "      <td>0.407863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               test_accuracy  test_loss  \\\n",
       "task      subtask          tokenizer                                      \n",
       "p_covid   p_covid_sub      hf_2_5M_tokenizer        0.725907   0.742033   \n",
       "                           hf_5M_rc_tokenizer       0.726670   0.745418   \n",
       "                           hf_5M_tokenizer          0.726403   0.742635   \n",
       "                           hs_2_5M_tokenizer        0.716138   0.758272   \n",
       "                           hs_5M_tokenizer          0.714854   0.758530   \n",
       "prom_300  prom_300_all     hf_2_5M_tokenizer        0.871378   0.352145   \n",
       "                           hf_5M_rc_tokenizer       0.878510   0.338742   \n",
       "                           hf_5M_tokenizer          0.873874   0.349040   \n",
       "                           hs_2_5M_tokenizer        0.869163   0.338676   \n",
       "                           hs_5M_tokenizer          0.868919   0.339153   \n",
       "          prom_300_notata  hf_2_5M_tokenizer        0.915688   0.262344   \n",
       "                           hf_5M_rc_tokenizer       0.915123   0.259944   \n",
       "                           hf_5M_tokenizer          0.912296   0.267181   \n",
       "                           hs_2_5M_tokenizer        0.909239   0.267065   \n",
       "                           hs_5M_tokenizer          0.910600   0.266214   \n",
       "          prom_300_tata    hf_2_5M_tokenizer        0.627877   0.659496   \n",
       "                           hf_5M_rc_tokenizer       0.632409   0.664721   \n",
       "                           hf_5M_tokenizer          0.628784   0.656574   \n",
       "                           hs_2_5M_tokenizer        0.617002   0.656175   \n",
       "                           hs_5M_tokenizer          0.617183   0.654632   \n",
       "prom_core prom_core_all    hf_2_5M_tokenizer        0.775473   0.484761   \n",
       "                           hf_5M_rc_tokenizer       0.777290   0.485933   \n",
       "                           hf_5M_tokenizer          0.777346   0.481766   \n",
       "                           hs_2_5M_tokenizer        0.764337   0.491055   \n",
       "                           hs_5M_tokenizer          0.765803   0.498189   \n",
       "          prom_core_notata hf_2_5M_tokenizer        0.787790   0.466253   \n",
       "                           hf_5M_rc_tokenizer       0.786132   0.464216   \n",
       "                           hf_5M_tokenizer          0.786048   0.467033   \n",
       "                           hs_2_5M_tokenizer        0.790277   0.474335   \n",
       "                           hs_5M_tokenizer          0.784813   0.471370   \n",
       "          prom_core_tata   hf_2_5M_tokenizer        0.704405   0.585505   \n",
       "                           hf_5M_rc_tokenizer       0.710350   0.583134   \n",
       "                           hf_5M_tokenizer          0.701468   0.575317   \n",
       "                           hs_2_5M_tokenizer        0.704527   0.610615   \n",
       "                           hs_5M_tokenizer          0.702374   0.614878   \n",
       "\n",
       "                                                test_f1  test_precision  \\\n",
       "task      subtask          tokenizer                                      \n",
       "p_covid   p_covid_sub      hf_2_5M_tokenizer   0.728841        0.737226   \n",
       "                           hf_5M_rc_tokenizer  0.730243        0.739790   \n",
       "                           hf_5M_tokenizer     0.729169        0.737896   \n",
       "                           hs_2_5M_tokenizer   0.719503        0.730047   \n",
       "                           hs_5M_tokenizer     0.718047        0.728335   \n",
       "prom_300  prom_300_all     hf_2_5M_tokenizer   0.871338        0.871839   \n",
       "                           hf_5M_rc_tokenizer  0.878417        0.879330   \n",
       "                           hf_5M_tokenizer     0.873853        0.874168   \n",
       "                           hs_2_5M_tokenizer   0.869140        0.869476   \n",
       "                           hs_5M_tokenizer     0.868884        0.869356   \n",
       "          prom_300_notata  hf_2_5M_tokenizer   0.915669        0.916373   \n",
       "                           hf_5M_rc_tokenizer  0.915094        0.916113   \n",
       "                           hf_5M_tokenizer     0.912253        0.913449   \n",
       "                           hs_2_5M_tokenizer   0.909214        0.910094   \n",
       "                           hs_5M_tokenizer     0.910579        0.911293   \n",
       "          prom_300_tata    hf_2_5M_tokenizer   0.623024        0.639055   \n",
       "                           hf_5M_rc_tokenizer  0.631270        0.635752   \n",
       "                           hf_5M_tokenizer     0.622511        0.643726   \n",
       "                           hs_2_5M_tokenizer   0.601076        0.640462   \n",
       "                           hs_5M_tokenizer     0.600313        0.642398   \n",
       "prom_core prom_core_all    hf_2_5M_tokenizer   0.775374        0.776058   \n",
       "                           hf_5M_rc_tokenizer  0.776954        0.779143   \n",
       "                           hf_5M_tokenizer     0.777287        0.777715   \n",
       "                           hs_2_5M_tokenizer   0.763688        0.767568   \n",
       "                           hs_5M_tokenizer     0.765413        0.767783   \n",
       "          prom_core_notata hf_2_5M_tokenizer   0.787553        0.789133   \n",
       "                           hf_5M_rc_tokenizer  0.785875        0.787356   \n",
       "                           hf_5M_tokenizer     0.785691        0.788042   \n",
       "                           hs_2_5M_tokenizer   0.790163        0.790980   \n",
       "                           hs_5M_tokenizer     0.784727        0.785285   \n",
       "          prom_core_tata   hf_2_5M_tokenizer   0.702287        0.710445   \n",
       "                           hf_5M_rc_tokenizer  0.707155        0.720400   \n",
       "                           hf_5M_tokenizer     0.700007        0.705959   \n",
       "                           hs_2_5M_tokenizer   0.703890        0.706026   \n",
       "                           hs_5M_tokenizer     0.701044        0.705566   \n",
       "\n",
       "                                               test_recall  test_mcc  \n",
       "task      subtask          tokenizer                                  \n",
       "p_covid   p_covid_sub      hf_2_5M_tokenizer      0.724557  0.690772  \n",
       "                           hf_5M_rc_tokenizer     0.725364  0.691687  \n",
       "                           hf_5M_tokenizer        0.725061  0.691395  \n",
       "                           hs_2_5M_tokenizer      0.714839  0.679951  \n",
       "                           hs_5M_tokenizer        0.713597  0.678488  \n",
       "prom_300  prom_300_all     hf_2_5M_tokenizer      0.871411  0.743249  \n",
       "                           hf_5M_rc_tokenizer     0.878394  0.757722  \n",
       "                           hf_5M_tokenizer        0.873923  0.748091  \n",
       "                           hs_2_5M_tokenizer      0.869212  0.738688  \n",
       "                           hs_5M_tokenizer        0.868965  0.738321  \n",
       "          prom_300_notata  hf_2_5M_tokenizer      0.915885  0.832257  \n",
       "                           hf_5M_rc_tokenizer     0.915363  0.831475  \n",
       "                           hf_5M_tokenizer        0.912500  0.825948  \n",
       "                           hs_2_5M_tokenizer      0.909452  0.819545  \n",
       "                           hs_5M_tokenizer        0.910784  0.822077  \n",
       "          prom_300_tata    hf_2_5M_tokenizer      0.630745  0.269551  \n",
       "                           hf_5M_rc_tokenizer     0.633645  0.269383  \n",
       "                           hf_5M_tokenizer        0.632432  0.275800  \n",
       "                           hs_2_5M_tokenizer      0.620445  0.258924  \n",
       "                           hs_5M_tokenizer        0.621084  0.261226  \n",
       "prom_core prom_core_all    hf_2_5M_tokenizer      0.775523  0.551580  \n",
       "                           hf_5M_rc_tokenizer     0.777390  0.556528  \n",
       "                           hf_5M_tokenizer        0.777388  0.555102  \n",
       "                           hs_2_5M_tokenizer      0.764475  0.532029  \n",
       "                           hs_5M_tokenizer        0.765910  0.533689  \n",
       "          prom_core_notata hf_2_5M_tokenizer      0.787812  0.576942  \n",
       "                           hf_5M_rc_tokenizer     0.786096  0.573447  \n",
       "                           hf_5M_tokenizer        0.786095  0.574132  \n",
       "                           hs_2_5M_tokenizer      0.790310  0.581289  \n",
       "                           hs_5M_tokenizer        0.784818  0.570103  \n",
       "          prom_core_tata   hf_2_5M_tokenizer      0.704728  0.415053  \n",
       "                           hf_5M_rc_tokenizer     0.710653  0.430899  \n",
       "                           hf_5M_tokenizer        0.701864  0.407780  \n",
       "                           hs_2_5M_tokenizer      0.704399  0.410419  \n",
       "                           hs_5M_tokenizer        0.702328  0.407863  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_subtask_metrics = tagged_runs.groupby(['task', 'subtask', 'tokenizer']).agg({\n",
    "\t\"test_accuracy\": \"mean\", \n",
    "\t\"test_loss\": \"mean\", \n",
    "\t\"test_f1\": \"mean\", \n",
    "\t\"test_precision\": \"mean\", \n",
    "\t\"test_recall\": \"mean\", \n",
    "\t\"test_mcc\": \"mean\"\n",
    "})\n",
    "mean_subtask_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['prom_300', 'prom_core']\n",
    "subtasks = ['_all', '_notata', '_tata']\n",
    "columns = ['test_accuracy', 'test_loss', 'test_f1', 'test_precision', 'test_recall', 'test_mcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: prom_300\n",
      " Subtask: _all\n",
      "Delta test_accuracy: 0.0096\n",
      "Delta test_loss: 0.0135\n",
      "Delta test_f1: 0.0095\n",
      "Delta test_precision: 0.0100\n",
      "Delta test_recall: 0.0094\n",
      "Delta test_mcc: 0.0194\n",
      " Subtask: _notata\n",
      "Delta test_accuracy: 0.0064\n",
      "Delta test_loss: 0.0072\n",
      "Delta test_f1: 0.0065\n",
      "Delta test_precision: 0.0063\n",
      "Delta test_recall: 0.0064\n",
      "Delta test_mcc: 0.0127\n",
      " Subtask: _tata\n",
      "Delta test_accuracy: 0.0154\n",
      "Delta test_loss: 0.0101\n",
      "Delta test_f1: 0.0310\n",
      "Delta test_precision: 0.0080\n",
      "Delta test_recall: 0.0132\n",
      "Delta test_mcc: 0.0169\n",
      "Task: prom_core\n",
      " Subtask: _all\n",
      "Delta test_accuracy: 0.0130\n",
      "Delta test_loss: 0.0164\n",
      "Delta test_f1: 0.0136\n",
      "Delta test_precision: 0.0116\n",
      "Delta test_recall: 0.0129\n",
      "Delta test_mcc: 0.0245\n",
      " Subtask: _notata\n",
      "Delta test_accuracy: 0.0055\n",
      "Delta test_loss: 0.0101\n",
      "Delta test_f1: 0.0054\n",
      "Delta test_precision: 0.0057\n",
      "Delta test_recall: 0.0055\n",
      "Delta test_mcc: 0.0112\n",
      " Subtask: _tata\n",
      "Delta test_accuracy: 0.0089\n",
      "Delta test_loss: 0.0396\n",
      "Delta test_f1: 0.0071\n",
      "Delta test_precision: 0.0148\n",
      "Delta test_recall: 0.0088\n",
      "Delta test_mcc: 0.0231\n",
      "Covid\n",
      "Delta test_accuracy: 0.0118\n",
      "Delta test_loss: 0.0165\n",
      "Delta test_f1: 0.0122\n",
      "Delta test_precision: 0.0115\n",
      "Delta test_recall: 0.0118\n",
      "Delta test_mcc: 0.0132\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "\tprint(f\"Task: {task}\")\n",
    "\tfor subtask in subtasks:\n",
    "\t\tprint(f\" Subtask: {subtask}\")\n",
    "\t\tfor col in columns:\n",
    "\t\t\tdelta = mean_subtask_metrics.loc[task].loc[f'{task}{subtask}'][col].max() - mean_subtask_metrics.loc[task].loc[f'{task}{subtask}'][col].min()\n",
    "\t\t\tprint(f\"Delta {col}: {delta:.4f}\")\n",
    "\n",
    "print('Covid')\n",
    "for col in columns:\n",
    "\tdelta = mean_subtask_metrics.loc['p_covid'].loc['p_covid_sub'][col].max()-mean_subtask_metrics.loc['p_covid'].loc['p_covid_sub'][col].min()\n",
    "\tprint(f\"Delta {col}: {delta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>species_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  \\\n",
       "0             5.1          3.5           1.4          0.2     setosa   \n",
       "1             4.9          3.0           1.4          0.2     setosa   \n",
       "2             4.7          3.2           1.3          0.2     setosa   \n",
       "3             4.6          3.1           1.5          0.2     setosa   \n",
       "4             5.0          3.6           1.4          0.2     setosa   \n",
       "..            ...          ...           ...          ...        ...   \n",
       "145           6.7          3.0           5.2          2.3  virginica   \n",
       "146           6.3          2.5           5.0          1.9  virginica   \n",
       "147           6.5          3.0           5.2          2.0  virginica   \n",
       "148           6.2          3.4           5.4          2.3  virginica   \n",
       "149           5.9          3.0           5.1          1.8  virginica   \n",
       "\n",
       "     species_id  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "..          ...  \n",
       "145           3  \n",
       "146           3  \n",
       "147           3  \n",
       "148           3  \n",
       "149           3  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = px.data.iris()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "test_accuracy=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x0": " ",
         "xaxis": "x",
         "y": {
          "bdata": "OF5eV6A65z8CS+WR4UDnPwHkI2myPuc/SeYNyJrq5j/lmJimFODmPw==",
          "dtype": "f8"
         },
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "test_accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, y=\"test_accuracy\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "box": {
          "visible": false
         },
         "hovertemplate": "test_accuracy=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "scalegroup": "True",
         "showlegend": false,
         "type": "violin",
         "x0": " ",
         "xaxis": "x",
         "y": {
          "bdata": "OF5eV6A65z8CS+WR4UDnPwHkI2myPuc/SeYNyJrq5j/lmJimFODmPw==",
          "dtype": "f8"
         },
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "violinmode": "group",
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "test_accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = mean_subtask_metrics.loc['p_covid'].loc['p_covid_sub']\n",
    "fig = px.violin(df, y=\"test_accuracy\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8689189189189189)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_subtask_metrics.loc['prom_300'].loc['prom_300_all']['test_accuracy'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_subtask_metrics.to_csv(\"mean_finetuning_subtask_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th>task</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">scenario1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">p_covid</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.726403</td>\n",
       "      <td>0.742635</td>\n",
       "      <td>0.729169</td>\n",
       "      <td>0.737896</td>\n",
       "      <td>0.725061</td>\n",
       "      <td>0.691395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.714854</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>0.718047</td>\n",
       "      <td>0.728335</td>\n",
       "      <td>0.713597</td>\n",
       "      <td>0.678488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_300</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.804985</td>\n",
       "      <td>0.424265</td>\n",
       "      <td>0.802873</td>\n",
       "      <td>0.810448</td>\n",
       "      <td>0.806285</td>\n",
       "      <td>0.616613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.798901</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.793259</td>\n",
       "      <td>0.807682</td>\n",
       "      <td>0.800278</td>\n",
       "      <td>0.607208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_core</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.754954</td>\n",
       "      <td>0.508039</td>\n",
       "      <td>0.754328</td>\n",
       "      <td>0.757239</td>\n",
       "      <td>0.755116</td>\n",
       "      <td>0.512338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.750997</td>\n",
       "      <td>0.528146</td>\n",
       "      <td>0.750395</td>\n",
       "      <td>0.752878</td>\n",
       "      <td>0.751019</td>\n",
       "      <td>0.503885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">scenario2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">p_covid</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.725907</td>\n",
       "      <td>0.742033</td>\n",
       "      <td>0.728841</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.724557</td>\n",
       "      <td>0.690772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.726670</td>\n",
       "      <td>0.745418</td>\n",
       "      <td>0.730243</td>\n",
       "      <td>0.739790</td>\n",
       "      <td>0.725364</td>\n",
       "      <td>0.691687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.716138</td>\n",
       "      <td>0.758272</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>0.730047</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.679951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_300</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.804981</td>\n",
       "      <td>0.424662</td>\n",
       "      <td>0.803344</td>\n",
       "      <td>0.809089</td>\n",
       "      <td>0.806014</td>\n",
       "      <td>0.615019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.808680</td>\n",
       "      <td>0.421136</td>\n",
       "      <td>0.808260</td>\n",
       "      <td>0.810398</td>\n",
       "      <td>0.809134</td>\n",
       "      <td>0.619527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.798468</td>\n",
       "      <td>0.420639</td>\n",
       "      <td>0.793143</td>\n",
       "      <td>0.806677</td>\n",
       "      <td>0.799703</td>\n",
       "      <td>0.605719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_core</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.755889</td>\n",
       "      <td>0.512173</td>\n",
       "      <td>0.755071</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.756021</td>\n",
       "      <td>0.514525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.757924</td>\n",
       "      <td>0.511094</td>\n",
       "      <td>0.756661</td>\n",
       "      <td>0.762300</td>\n",
       "      <td>0.758046</td>\n",
       "      <td>0.520291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.753047</td>\n",
       "      <td>0.525335</td>\n",
       "      <td>0.752581</td>\n",
       "      <td>0.754858</td>\n",
       "      <td>0.753061</td>\n",
       "      <td>0.507912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        test_accuracy  test_loss   test_f1  \\\n",
       "scenario  task      tokenizer                                                \n",
       "scenario1 p_covid   hf_5M_tokenizer          0.726403   0.742635  0.729169   \n",
       "                    hs_5M_tokenizer          0.714854   0.758530  0.718047   \n",
       "          prom_300  hf_5M_tokenizer          0.804985   0.424265  0.802873   \n",
       "                    hs_5M_tokenizer          0.798901   0.420000  0.793259   \n",
       "          prom_core hf_5M_tokenizer          0.754954   0.508039  0.754328   \n",
       "                    hs_5M_tokenizer          0.750997   0.528146  0.750395   \n",
       "scenario2 p_covid   hf_2_5M_tokenizer        0.725907   0.742033  0.728841   \n",
       "                    hf_5M_rc_tokenizer       0.726670   0.745418  0.730243   \n",
       "                    hs_2_5M_tokenizer        0.716138   0.758272  0.719503   \n",
       "          prom_300  hf_2_5M_tokenizer        0.804981   0.424662  0.803344   \n",
       "                    hf_5M_rc_tokenizer       0.808680   0.421136  0.808260   \n",
       "                    hs_2_5M_tokenizer        0.798468   0.420639  0.793143   \n",
       "          prom_core hf_2_5M_tokenizer        0.755889   0.512173  0.755071   \n",
       "                    hf_5M_rc_tokenizer       0.757924   0.511094  0.756661   \n",
       "                    hs_2_5M_tokenizer        0.753047   0.525335  0.752581   \n",
       "\n",
       "                                        test_precision  test_recall  test_mcc  \n",
       "scenario  task      tokenizer                                                  \n",
       "scenario1 p_covid   hf_5M_tokenizer           0.737896     0.725061  0.691395  \n",
       "                    hs_5M_tokenizer           0.728335     0.713597  0.678488  \n",
       "          prom_300  hf_5M_tokenizer           0.810448     0.806285  0.616613  \n",
       "                    hs_5M_tokenizer           0.807682     0.800278  0.607208  \n",
       "          prom_core hf_5M_tokenizer           0.757239     0.755116  0.512338  \n",
       "                    hs_5M_tokenizer           0.752878     0.751019  0.503885  \n",
       "scenario2 p_covid   hf_2_5M_tokenizer         0.737226     0.724557  0.690772  \n",
       "                    hf_5M_rc_tokenizer        0.739790     0.725364  0.691687  \n",
       "                    hs_2_5M_tokenizer         0.730047     0.714839  0.679951  \n",
       "          prom_300  hf_2_5M_tokenizer         0.809089     0.806014  0.615019  \n",
       "                    hf_5M_rc_tokenizer        0.810398     0.809134  0.619527  \n",
       "                    hs_2_5M_tokenizer         0.806677     0.799703  0.605719  \n",
       "          prom_core hf_2_5M_tokenizer         0.758545     0.756021  0.514525  \n",
       "                    hf_5M_rc_tokenizer        0.762300     0.758046  0.520291  \n",
       "                    hs_2_5M_tokenizer         0.754858     0.753061  0.507912  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_task_metrics = tagged_runs.groupby(['scenario', 'task', 'tokenizer']).agg({\n",
    "\t\"test_accuracy\": \"mean\", \n",
    "\t\"test_loss\": \"mean\", \n",
    "\t\"test_f1\": \"mean\", \n",
    "\t\"test_precision\": \"mean\", \n",
    "\t\"test_recall\": \"mean\", \n",
    "\t\"test_mcc\": \"mean\"\n",
    "})\n",
    "mean_task_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_task_metrics.to_csv(\"mean_finetuning_task_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = pd.read_csv(\"mean_metrics.csv\", index_col=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity, project = \"josefine-busch-htw-berlin\", \"ma_finetuning\"\n",
    "runs = api.runs(f\"{entity}/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, tags, eval_runtime, train_runtime = [], [], [], []\n",
    "for run in runs:\n",
    "\tnames.append(run.name)\n",
    "\ttags.append(run.tags)\n",
    "\teval_runtime.append(run.summary.get(\"eval/runtime\", np.nan))\n",
    "\ttrain_runtime.append(run.summary.get(\"train_runtime\", np.nan))\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "\t{\n",
    "\t\"run_name\": names,\n",
    "\t\"eval_runtime\": eval_runtime,\n",
    "\t\"train_runtime\": train_runtime\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>job_id</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>task</th>\n",
       "      <th>subtask</th>\n",
       "      <th>scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_al...</td>\n",
       "      <td>4.2485</td>\n",
       "      <td>829.0819</td>\n",
       "      <td>14290</td>\n",
       "      <td>hf_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_all</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_al...</td>\n",
       "      <td>4.1702</td>\n",
       "      <td>828.8850</td>\n",
       "      <td>14293</td>\n",
       "      <td>hs_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_all</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_no...</td>\n",
       "      <td>3.9872</td>\n",
       "      <td>755.6423</td>\n",
       "      <td>14290</td>\n",
       "      <td>hf_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_notata</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_no...</td>\n",
       "      <td>3.7640</td>\n",
       "      <td>746.8029</td>\n",
       "      <td>14293</td>\n",
       "      <td>hs_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_notata</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_ta...</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>254.2423</td>\n",
       "      <td>14290</td>\n",
       "      <td>hf_5M_tokenizer</td>\n",
       "      <td>prom_core</td>\n",
       "      <td>prom_core_tata</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            run_name  eval_runtime  \\\n",
       "0  HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_al...        4.2485   \n",
       "1  HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_al...        4.1702   \n",
       "2  HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_no...        3.9872   \n",
       "3  HF_HS_5M_NRC_150K_42_v6_3e-5_prom_prom_core_no...        3.7640   \n",
       "4  HF_HF_5M_NRC_150K_42_v9_3e-5_prom_prom_core_ta...        0.4620   \n",
       "\n",
       "   train_runtime job_id        tokenizer       task           subtask  \\\n",
       "0       829.0819  14290  hf_5M_tokenizer  prom_core     prom_core_all   \n",
       "1       828.8850  14293  hs_5M_tokenizer  prom_core     prom_core_all   \n",
       "2       755.6423  14290  hf_5M_tokenizer  prom_core  prom_core_notata   \n",
       "3       746.8029  14293  hs_5M_tokenizer  prom_core  prom_core_notata   \n",
       "4       254.2423  14290  hf_5M_tokenizer  prom_core    prom_core_tata   \n",
       "\n",
       "    scenario  \n",
       "0  scenario1  \n",
       "1  scenario1  \n",
       "2  scenario1  \n",
       "3  scenario1  \n",
       "4  scenario1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df = pd.DataFrame(tags, columns=['job_id', 'tokenizer', 'task', 'subtask', 'scenario'])\n",
    "tagged_runs = pd.concat([runs_df, tags_df], axis=1)\n",
    "tagged_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>train_runtime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th>task</th>\n",
       "      <th>subtask</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">scenario1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">prom_300</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_300_all</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>4.371867</td>\n",
       "      <td>852.207767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>4.216033</td>\n",
       "      <td>840.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_300_notata</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>3.841800</td>\n",
       "      <td>751.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>3.808033</td>\n",
       "      <td>758.543167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_300_tata</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.459900</td>\n",
       "      <td>252.795867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.457133</td>\n",
       "      <td>251.419033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">prom_core</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_core_all</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>4.191900</td>\n",
       "      <td>830.518833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>4.178767</td>\n",
       "      <td>825.373133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_core_notata</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>3.852000</td>\n",
       "      <td>751.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>3.805200</td>\n",
       "      <td>745.836033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">prom_core_tata</th>\n",
       "      <th>hf_5M_tokenizer</th>\n",
       "      <td>0.453067</td>\n",
       "      <td>251.439633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_5M_tokenizer</th>\n",
       "      <td>0.451233</td>\n",
       "      <td>249.886267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">scenario2</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">prom_300</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_300_all</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>4.312250</td>\n",
       "      <td>837.710950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>4.309700</td>\n",
       "      <td>834.246133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>4.226033</td>\n",
       "      <td>837.304933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_300_notata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>3.835950</td>\n",
       "      <td>745.566250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>3.800267</td>\n",
       "      <td>738.036867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>3.803800</td>\n",
       "      <td>755.752033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_300_tata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.451300</td>\n",
       "      <td>248.578350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.450800</td>\n",
       "      <td>247.341633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.456067</td>\n",
       "      <td>252.326833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">prom_core</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_core_all</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>4.190000</td>\n",
       "      <td>823.364450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>4.138467</td>\n",
       "      <td>817.474233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>4.157067</td>\n",
       "      <td>821.552933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_core_notata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>3.691000</td>\n",
       "      <td>737.370950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>3.723667</td>\n",
       "      <td>733.568267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>3.741533</td>\n",
       "      <td>735.964267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">prom_core_tata</th>\n",
       "      <th>hf_2_5M_tokenizer</th>\n",
       "      <td>0.446750</td>\n",
       "      <td>245.309250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hf_5M_rc_tokenizer</th>\n",
       "      <td>0.442833</td>\n",
       "      <td>244.558533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_2_5M_tokenizer</th>\n",
       "      <td>0.450200</td>\n",
       "      <td>248.943733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         eval_runtime  \\\n",
       "scenario  task      subtask          tokenizer                          \n",
       "scenario1 prom_300  prom_300_all     hf_5M_tokenizer         4.371867   \n",
       "                                     hs_5M_tokenizer         4.216033   \n",
       "                    prom_300_notata  hf_5M_tokenizer         3.841800   \n",
       "                                     hs_5M_tokenizer         3.808033   \n",
       "                    prom_300_tata    hf_5M_tokenizer         0.459900   \n",
       "                                     hs_5M_tokenizer         0.457133   \n",
       "          prom_core prom_core_all    hf_5M_tokenizer         4.191900   \n",
       "                                     hs_5M_tokenizer         4.178767   \n",
       "                    prom_core_notata hf_5M_tokenizer         3.852000   \n",
       "                                     hs_5M_tokenizer         3.805200   \n",
       "                    prom_core_tata   hf_5M_tokenizer         0.453067   \n",
       "                                     hs_5M_tokenizer         0.451233   \n",
       "scenario2 prom_300  prom_300_all     hf_2_5M_tokenizer       4.312250   \n",
       "                                     hf_5M_rc_tokenizer      4.309700   \n",
       "                                     hs_2_5M_tokenizer       4.226033   \n",
       "                    prom_300_notata  hf_2_5M_tokenizer       3.835950   \n",
       "                                     hf_5M_rc_tokenizer      3.800267   \n",
       "                                     hs_2_5M_tokenizer       3.803800   \n",
       "                    prom_300_tata    hf_2_5M_tokenizer       0.451300   \n",
       "                                     hf_5M_rc_tokenizer      0.450800   \n",
       "                                     hs_2_5M_tokenizer       0.456067   \n",
       "          prom_core prom_core_all    hf_2_5M_tokenizer       4.190000   \n",
       "                                     hf_5M_rc_tokenizer      4.138467   \n",
       "                                     hs_2_5M_tokenizer       4.157067   \n",
       "                    prom_core_notata hf_2_5M_tokenizer       3.691000   \n",
       "                                     hf_5M_rc_tokenizer      3.723667   \n",
       "                                     hs_2_5M_tokenizer       3.741533   \n",
       "                    prom_core_tata   hf_2_5M_tokenizer       0.446750   \n",
       "                                     hf_5M_rc_tokenizer      0.442833   \n",
       "                                     hs_2_5M_tokenizer       0.450200   \n",
       "\n",
       "                                                         train_runtime  \n",
       "scenario  task      subtask          tokenizer                          \n",
       "scenario1 prom_300  prom_300_all     hf_5M_tokenizer        852.207767  \n",
       "                                     hs_5M_tokenizer        840.394500  \n",
       "                    prom_300_notata  hf_5M_tokenizer        751.551800  \n",
       "                                     hs_5M_tokenizer        758.543167  \n",
       "                    prom_300_tata    hf_5M_tokenizer        252.795867  \n",
       "                                     hs_5M_tokenizer        251.419033  \n",
       "          prom_core prom_core_all    hf_5M_tokenizer        830.518833  \n",
       "                                     hs_5M_tokenizer        825.373133  \n",
       "                    prom_core_notata hf_5M_tokenizer        751.597700  \n",
       "                                     hs_5M_tokenizer        745.836033  \n",
       "                    prom_core_tata   hf_5M_tokenizer        251.439633  \n",
       "                                     hs_5M_tokenizer        249.886267  \n",
       "scenario2 prom_300  prom_300_all     hf_2_5M_tokenizer      837.710950  \n",
       "                                     hf_5M_rc_tokenizer     834.246133  \n",
       "                                     hs_2_5M_tokenizer      837.304933  \n",
       "                    prom_300_notata  hf_2_5M_tokenizer      745.566250  \n",
       "                                     hf_5M_rc_tokenizer     738.036867  \n",
       "                                     hs_2_5M_tokenizer      755.752033  \n",
       "                    prom_300_tata    hf_2_5M_tokenizer      248.578350  \n",
       "                                     hf_5M_rc_tokenizer     247.341633  \n",
       "                                     hs_2_5M_tokenizer      252.326833  \n",
       "          prom_core prom_core_all    hf_2_5M_tokenizer      823.364450  \n",
       "                                     hf_5M_rc_tokenizer     817.474233  \n",
       "                                     hs_2_5M_tokenizer      821.552933  \n",
       "                    prom_core_notata hf_2_5M_tokenizer      737.370950  \n",
       "                                     hf_5M_rc_tokenizer     733.568267  \n",
       "                                     hs_2_5M_tokenizer      735.964267  \n",
       "                    prom_core_tata   hf_2_5M_tokenizer      245.309250  \n",
       "                                     hf_5M_rc_tokenizer     244.558533  \n",
       "                                     hs_2_5M_tokenizer      248.943733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_runtimes = tagged_runs.groupby(['scenario', 'task', 'subtask', 'tokenizer']).agg({\n",
    "\t\"eval_runtime\": \"mean\",\n",
    "\t\"train_runtime\": \"mean\"\n",
    "})\n",
    "\n",
    "mean_runtimes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
